```markdown
# ğŸš– NYC Yellow Taxi Riding Prediction

Ce projet permet de prÃ©dire le nombre de passagers pour les trajets de taxi Ã  New York en utilisant un modÃ¨le de rÃ©gression Random Forest entraÃ®nÃ© avec PySpark.  
L'application est composÃ©e d'un **backend (API Flask) ğŸ–¥ï¸** et d'un **frontend (Streamlit) ğŸ¨**.

---

## ğŸ“Œ Table des matiÃ¨res

1. [ğŸ”§ PrÃ©requis](#prÃ©requis)
2. [ğŸ“‚ Structure du projet](#structure-du-projet)
3. [ğŸ“¥ Installation](#installation)
4. [ğŸš€ ExÃ©cution](#exÃ©cution)
5. [ğŸ–±ï¸ Utilisation](#utilisation)
6. [ğŸ“¡ API Endpoints](#api-endpoints)
7. [ğŸ› ï¸ Technologies utilisÃ©es](#technologies-utilisÃ©es)
8. [ğŸ‘¨â€ğŸ’» Auteurs](#auteurs)

---

## ğŸ”§ PrÃ©requis

Avant de commencer, assurez-vous d'avoir les Ã©lÃ©ments suivants installÃ©s sur votre machine :

- ğŸ³ **Docker** : Pour exÃ©cuter les conteneurs.
- ğŸ› ï¸ **Docker Compose** : Pour gÃ©rer les services multi-conteneurs.
- ğŸ”— **Git** : Pour cloner le dÃ©pÃ´t.

---

## ğŸ“‚ Structure du projet

Le projet est structurÃ© comme suit :

```
project/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ Dockerfile ğŸ“„
â”‚   â”œâ”€â”€ backend_api.py ğŸ–¥ï¸
â”‚   â”œâ”€â”€ requirements.txt ğŸ“œ
â”‚   â”œâ”€â”€ spark-3.5.3-bin-hadoop3.tgz ğŸ“¦  # Fichier Spark
â”‚   â””â”€â”€ random_forest_model/ ğŸ“  # Dossier contenant le modÃ¨le
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ Dockerfile ğŸ“„
â”‚   â”œâ”€â”€ frontend.py ğŸ¨
â”‚   â””â”€â”€ requirements.txt ğŸ“œ
â””â”€â”€ docker-compose.yml âš™ï¸
```

ğŸš¨ **Ajoutez le fichier lourd dans `.gitignore` pour Ã©viter de le pousser sur GitHub** :  

ğŸ“œ **Fichier `.gitignore`** :
```
backend/spark-3.5.3-bin-hadoop3.tgz
```

---

## ğŸ“¥ Installation

1. **Cloner le dÃ©pÃ´t** ğŸ›ï¸ :
   ```bash
   git clone https://github.com/votre-utilisateur/NYC-Yellow-Taxi-Riding-Prediction.git
   cd NYC-Yellow-Taxi-Riding-Prediction
   ```

2. **Construire les images Docker** ğŸ—ï¸ :
   - Le fichier `spark-3.5.3-bin-hadoop3.tgz` est inclus dans le dossier `backend`.
   - ExÃ©cutez la commande suivante pour construire les images :
     ```bash
     docker-compose build
     ```

---

## ğŸš€ ExÃ©cution

1. **DÃ©marrer les conteneurs** ğŸ :
   ```bash
   docker-compose up
   ```

2. **AccÃ©der aux services** ğŸŒ :
   - **Backend (API Flask) ğŸ–¥ï¸** : `http://127.0.0.1:5000`
   - **Frontend (Streamlit) ğŸ¨** : `http://127.0.0.1:8501`

---

## ğŸ–±ï¸ Utilisation

1. **Ouvrir l'interface Streamlit** :
   - AccÃ©dez Ã  `http://127.0.0.1:8501` dans votre navigateur.
   - Saisissez les caractÃ©ristiques du trajet (heure, jour ouvrÃ©, mÃ©tÃ©o, etc.).
   - Cliquez sur "PrÃ©dire le nombre de passagers" pour obtenir la prÃ©diction.

2. **Utiliser l'API Flask directement** :
   - Envoyez une requÃªte **POST** Ã  `http://127.0.0.1:5000/predict` avec un corps JSON :
     ```json
     {
       "hour": 10,
       "is_business_day": 1,
       "weather_index": 0,
       "temp_avg": 20,
       "distance_category_index": 1
     }
     ```
   - Exemple de rÃ©ponse :
     ```json
     {
       "prediction": 12.34
     }
     ```

---

## ğŸ“¡ API Endpoints

- **GET `/`** : Page d'accueil de l'API.
  - RÃ©ponse : `"Welcome to the NYC Taxi Prediction API! Use the /predict endpoint for predictions."`

- **POST `/predict`** : Effectue une prÃ©diction en fonction des caractÃ©ristiques du trajet.
  - Corps de la requÃªte (JSON) :
    ```json
    {
      "hour": 10,
      "is_business_day": 1,
      "weather_index": 0,
      "temp_avg": 20,
      "distance_category_index": 1
    }
    ```
  - RÃ©ponse (JSON) :
    ```json
    {
      "prediction": 12.34
    }
    ```

---

## ğŸ› ï¸ Technologies utilisÃ©es

- **Backend** :
  - Flask (Python) ğŸ : API REST
  - PySpark âš¡ : ModÃ¨le de prÃ©diction
  - Docker ğŸ³ : Conteneurisation

- **Frontend** :
  - Streamlit ğŸ¨ : Interface utilisateur
  - Docker ğŸ³ : Conteneurisation

- **Autres** :
  - Git ğŸ”— : Versionnement du code
  - Docker Compose âš™ï¸ : Gestion des services multi-conteneurs

---

## ğŸ‘¨â€ğŸ’» Auteurs

- **Myrem** ğŸ‘©â€ğŸ’» : DÃ©veloppeur principal
- **Ines** ğŸ‘©â€ğŸ’» : DÃ©veloppeur principal
- **Ousmane BA** ğŸ‘¨â€ğŸ’» : DÃ©veloppeur principal

---

## ğŸ“œ Licence

Ce projet est sous licence **MIT**. Voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

---

## â— Remarques

- Assurez-vous que le fichier `spark-3.5.3-bin-hadoop3.tgz` est bien dans le dossier `backend`.
- Si vous utilisez **Git LFS** pour les fichiers volumineux, configurez-le correctement.

---

## ğŸ¤ Contribuer

Les contributions sont **les bienvenues** ! ğŸš€ Pour contribuer :

1. **Forkez** le projet ğŸ´.
2. **CrÃ©ez** une branche (`git checkout -b feature/NouvelleFonctionnalitÃ©`).
3. **Committez** vos modifications (`git commit -m "Ajout d'une nouvelle fonctionnalitÃ©"`).
4. **Poussez** vers la branche (`git push origin feature/NouvelleFonctionnalitÃ©`).
5. **Ouvrez** une **Pull Request** ğŸ“¬.

---

## â“ Questions ou problÃ¨mes ?

Si vous avez des questions, ouvrez une **issue** sur GitHub ou contactez-moi ğŸ“© Ã  [bousmane733@gmail.com](mailto:bousmane733@gmail.com).
```
